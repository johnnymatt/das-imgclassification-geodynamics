{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fdfb24a8-cd53-468e-8242-49b3ff30bee2",
   "metadata": {},
   "source": [
    "///////////////////////////////////////////////////////////////////////// // // Â© University of Southampton IT Innovation Centre, 2023 // // Copyright in this software belongs to University of Southampton // IT Innovation Centre of University Road, Southampton, GB SO17 1BJ, UK. // // This software may not be used, sold, licensed, transferred, copied // or reproduced in whole or in part in any manner or form or in or // on any media by any person other than in accordance with the terms // of the Licence Agreement supplied with the software, or otherwise // without the prior written consent of the copyright owners. // // This software is distributed WITHOUT ANY WARRANTY, without even the // implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR // PURPOSE, except where stated in the Licence Agreement supplied with // the software. // //      Created By :          Ioannis Matthaiou //      Created Date :        22/02/2023 //      Created for Project : GEODYNAMICS // /////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d630c88f-602e-427d-87fb-78769a3cf2a4",
   "metadata": {},
   "source": [
    "RUN CODE FROM HERE Press ctrl + enter in each cell to run the code and observe output below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42435e3-bbaf-46ad-92a2-02fea5d93f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required libraries\n",
    "!pip install tensorflow matplotlib opencv-python pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f51e17-069c-4504-812d-7b3882441e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\yianniswork\\Desktop\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2 as cv\n",
    "import shutil\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "# Current working directory must be something like: C:\\Users\\<FULL_PATH>\\imgclass_test\n",
    "# If not change the current working directory, for instance,\n",
    "# os.chdir('C:\\Users\\<FULL_PATH>\\imgclass_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59186247-e267-4ab4-854d-be3e451ea03e",
   "metadata": {},
   "source": [
    "The following is a fixed set of parameters for loading the images. IMPORTANT: batch_size, img_width and img_height must never change.\n",
    "I have included a sample of 10 images in the folder test_images. You can remove those if you don't need them. Any images that you need to use to test the model must be added to the \"test_images\" folder. Run the code in the cell below to process the images that are on the test_images folder. A new folder will be created and the processed images will be stored on the test_images_prep folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa38f1d-4a79-47f4-82c5-19605e40eafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder created with absolute path: C:\\Users\\yianniswork\\Desktop\\test_images_prep\n"
     ]
    }
   ],
   "source": [
    "# Fixed set of parameters\n",
    "img_width, img_height = (256, 256)\n",
    "batch_size = 64\n",
    "crop_imgs = 0 # select 1 if images must be cropped\n",
    "stored_imgs_dir = './test_images/'\n",
    "new_stored_imgs_dir = './test_images_prep/'\n",
    "\n",
    "def cropimg(stored_imgs_dir,new_stored_imgs_dir,crop_imgs):  \n",
    "    \n",
    "    # Load image\n",
    "    #First get the list of images in the folder\n",
    "    stored_imgs_dir = stored_imgs_dir\n",
    "    new_stored_imgs_dir = new_stored_imgs_dir\n",
    "    list_of_original_images = os.listdir(stored_imgs_dir) # Path to images folder\n",
    "    \n",
    "    #Create a new directory to store the cropped images\n",
    "    if not os.path.exists(new_stored_imgs_dir):\n",
    "        print('Folder created with absolute path: '\n",
    "              + os.path.abspath(new_stored_imgs_dir))\n",
    "        os.mkdir(new_stored_imgs_dir)\n",
    "    else:\n",
    "        print('Folder already exists so any additional images will be added')\n",
    "    \n",
    "    # Cropping parameters\n",
    "    xcropmin = 150\n",
    "    ycropmin = 265\n",
    "    mainwidth = 1000\n",
    "    mainheight = 800\n",
    "    \n",
    "    #Iterate through the image_list\n",
    "    for image_path in list_of_original_images:\n",
    "        image_array = cv.imread(\n",
    "            stored_imgs_dir+image_path, \n",
    "            cv.IMREAD_GRAYSCALE)     \n",
    "        if crop_imgs == 1:\n",
    "            height,width = image_array.shape\n",
    "            cropped_image = image_array[ycropmin:mainheight,xcropmin:mainwidth] # Use array slicing to cut some part of the image\n",
    "        else:\n",
    "            cropped_image = image_array # No cropping\n",
    "    \n",
    "        # Write cropped image to Cropped Images folder\n",
    "        cv.imwrite(new_stored_imgs_dir+image_path[:-3]+'jpg',cropped_image)\n",
    "\n",
    "# Data preprocess using cropimg function and load using tensorflow pipeline\n",
    "cropimg(stored_imgs_dir,\n",
    "        new_stored_imgs_dir,crop_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea20e4f-e81e-4efe-95ee-bcdebaffe0c6",
   "metadata": {},
   "source": [
    "Run the following cell to format images into an appropriate tensorflow pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec54f6e-a54f-4137-a930-7e39b491214c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plt_2022-02-04_02.36.22.116360.jpg\n",
      "plt_2022-02-11_13.59.57.283316.jpg\n",
      "plt_2022-02-12_14.00.28.444328.jpg\n",
      "plt_2022-02-14_01.21.59.849543.jpg\n",
      "plt_2022-02-15_05.46.24.982109.jpg\n",
      "plt_2022-02-15_08.46.27.412065.jpg\n",
      "plt_2022-02-15_10.07.28.529347.jpg\n",
      "plt_2022-02-22_10.54.54.011347.jpg\n",
      "plt_2022-03-22_01.55.26.747745.jpg\n",
      "plt_2022-03-22_06.43.30.728986.jpg\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "listofimgs = os.listdir(new_stored_imgs_dir)\n",
    "Nimages = len(listofimgs)\n",
    "for img in listofimgs:\n",
    "    print(img)\n",
    "    img = tf.keras.utils.load_img(\n",
    "            os.path.join(new_stored_imgs_dir, img),\n",
    "            color_mode=\"grayscale\",\n",
    "            target_size=(img_height, img_width),\n",
    "            interpolation='nearest',\n",
    "            keep_aspect_ratio=False\n",
    "            )\n",
    "    img = tf.keras.utils.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    images.append(img)\n",
    "images = np.vstack(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc80a814-12b2-4456-a359-2f7ad3d1534b",
   "metadata": {},
   "source": [
    "Run the following cell to load the model from the saved_model folder and make predictions for each image. The code will generate a .csv file with the prediction results. The .csv file (named predictions_file.csv) will be located in the current working directory. There will be 4 columns on the predictions_file.csv. The first three are the probabilities of predicting the three classes: geophysical, not event and not geophysical:\r\n",
    "\r\n",
    "'geophysical': Geophysical events, i.e. tremors, earthquakes, etc.\r\n",
    "'not geophysical': Non geophysical events, i.e. whales, air guns, etc.\r\n",
    "'not event': Only background noise\r\n",
    "Remember: The .csv file must be closed before running the following cell.\r\n",
    "\r\n",
    "The following cell will also create 4 different folders:\r\n",
    "\r\n",
    "'geophysical': includes images predicted with high probability as being geophysical\r\n",
    "'nongeophysical': includes images predicted with high probability as being not geophysical (whales, ships, etc.)\r\n",
    "'nonevents': includes images predicted with high probability as being noise\r\n",
    "'lowprobability': includes images NOT predicted with high probability as being one of the above three classes. These are images that may have multiple events in them and the algorithm cannot assign high probability to a single class for it to be classified.\r\n",
    "The 'high probability' parameter may be changed by changing the abs_prob variable. Right now is at .75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b48fbc73-2bf7-4e51-b88d-601c5a98e5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "   geophysical  not event  not geophysical                           fileID\n",
      "0          1.0        0.0              0.0  _2022-02-04_02.36.22.116360.jpg\n",
      "1          1.0        0.0              0.0  _2022-02-11_13.59.57.283316.jpg\n",
      "2          0.0        0.0              1.0  _2022-02-12_14.00.28.444328.jpg\n",
      "3          1.0        0.0              0.0  _2022-02-14_01.21.59.849543.jpg\n",
      "4          1.0        0.0              0.0  _2022-02-15_05.46.24.982109.jpg\n",
      "5          0.0        0.0              1.0  _2022-02-15_08.46.27.412065.jpg\n",
      "6          1.0        0.0              0.0  _2022-02-15_10.07.28.529347.jpg\n",
      "7          0.0        1.0              0.0  _2022-02-22_10.54.54.011347.jpg\n",
      "8          0.0        0.0              1.0  _2022-03-22_01.55.26.747745.jpg\n",
      "9          0.0        0.0              1.0  _2022-03-22_06.43.30.728986.jpg\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "model_cnn = tf.keras.models.load_model('./10-04_18-14')\n",
    "test_predictions = model_cnn.predict(images)\n",
    "pred_prob = tf.nn.softmax(test_predictions) \n",
    "pred_prob = pred_prob.numpy()\n",
    "\n",
    "separator = 'plt'\n",
    "fileID = []\n",
    "for i in range(len(pred_prob)):\n",
    "    fileID.append(listofimgs[i].split(separator,1)[1])    \n",
    "\n",
    "df = pd.DataFrame(pred_prob, \n",
    "                  columns = ['geophysical','not event','not geophysical'])\n",
    "df['fileID'] = fileID\n",
    "print(df)\n",
    "print(type(df))\n",
    "df.to_csv(\n",
    "    './predictions_file.csv',\n",
    "    float_format='%.2f',\n",
    "    index=False) # Use Tab to seperate data\n",
    "\n",
    "predictions_folder = './predictions_categories'\n",
    "if os.path.exists(predictions_folder):\n",
    "    shutil.rmtree(os.path.abspath(predictions_folder))\n",
    "    print('Existing directory '+ predictions_folder +' has been deleted')\n",
    "os.mkdir(predictions_folder)\n",
    "    \n",
    "path_geoph = predictions_folder+'/geophysical'\n",
    "if not os.path.exists(path_geoph):\n",
    "    os.mkdir(path_geoph)\n",
    "path_nongeoph = predictions_folder+'/nongeophysical'\n",
    "if not os.path.exists(path_nongeoph):\n",
    "    os.mkdir(path_nongeoph)   \n",
    "path_nonevent = predictions_folder+'/nonevents'\n",
    "if not os.path.exists(path_nonevent):\n",
    "    os.mkdir(path_nonevent)\n",
    "path_lowprob = predictions_folder+'/lowprobability'\n",
    "if not os.path.exists(path_lowprob):\n",
    "    os.mkdir(path_lowprob)\n",
    "    \n",
    "abs_prob = 0.75\n",
    "\n",
    "for i in range(Nimages):      \n",
    "    if pred_prob[i,0] > abs_prob:   \n",
    "        cv.imwrite(path_geoph+'/'+fileID[i],images[i]) \n",
    "    elif pred_prob[i,1] > abs_prob:\n",
    "        cv.imwrite(path_nonevent+'/'+fileID[i],images[i])  \n",
    "    elif pred_prob[i,2] > abs_prob:\n",
    "        cv.imwrite(path_nongeoph+'/'+fileID[i],images[i])                        \n",
    "    else:\n",
    "        cv.imwrite(path_lowprob+'/'+fileID[i],images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b1640-638f-43cc-bf0e-386cd8db2b1d",
   "metadata": {},
   "source": [
    "The following code may be used to make predictions for a single image (located on the test_images_prep folder), by changing the img_fileID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f653631-7bd7-4469-9d19-99e5b74c0c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dir = './test_images_prep'\n",
    "img_fileID = '/plt_2022-02-04_02.36.22.116360.jpg'\n",
    "imgtest_or = tf.keras.utils.load_img(\n",
    "    test_data_dir+img_fileID,\n",
    "    color_mode=\"grayscale\",    \n",
    "    target_size=(img_width,img_height),\n",
    "    interpolation='nearest',\n",
    "    keep_aspect_ratio=False\n",
    "    )\n",
    "plt.imshow(imgtest_or)\n",
    "plt.show()\n",
    "x = tf.keras.utils.img_to_array(imgtest_or)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "test_prediction = model_cnn.predict(x, batch_size=batch_size)\n",
    "pred_prob_sngl = tf.nn.softmax(test_prediction[0,:])\n",
    "pred_prob_sngl = pred_prob_sngl.numpy()\n",
    "print(f\"Model predicts image with file name: \" + img_fileID[1:] + \" as being: \")\n",
    "print(f\"geophysical event with probability = {100 * (pred_prob_sngl[0]):.2f}%\")\n",
    "print(f\"non event / noise with probability = {100 * (pred_prob_sngl[1]):.2f}%\")\n",
    "print(f\"non geophysical event with probability = {100 * (pred_prob_sngl[2]):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
